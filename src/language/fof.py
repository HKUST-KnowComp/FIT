"""
A base class for existential first order formulas
It supports the verification and query answering tasks given the formula
For the verification, there is no free_vars
For the query answering, there should be at least one free_vars
Several assumptions about the formula
- In DNF
- Only with existential quantifier
The query is generated by the following steps:

>>>> Construct the conjunctive query skeleton:
    1. Define the number of terms, including
        - p existential vars
        - q free vars
        - r literals
        There are p + q + r terms
    2. Construct the edges between terms by random sampling, and then construct
        a connective graph, the edge is constructed by the certain ratio $P_e$
    3. Randomly corrupt the edges with negation $P_n$
<<<< In this way, the conjunctive query skeleton is constructed

>>>> Construct the DNF formula
    The key of DNF construction is that there must be at least one variable be
    shared in two conjunctive query
    1. determin the variables to be shared (more than one)
    2. determin the objects to be shared (not necessary more than one)
<<<<

>>>> Sampling accross the graph
    1. For question answering task
        1. sample the full graph,
            so that the predicates and objects are determined
        2. search over partial graph and full graph,
            and find out the answer tuples
    2. Instantiation of the query graph
<<<<
"""
import random
from abc import ABC, abstractmethod
from collections import defaultdict
import json
from typing import Dict, List
from random import sample

import numpy as np
import torch

from src.language.tnorm import Tnorm
from src.structure.neural_binary_predicate import NeuralBinaryPredicate
from src.structure.knowledge_graph import KnowledgeGraph, subgraph_matching, ground_variable, kg2matrix, \
    labeling_triples, label_triples_with_assign, ground_predicate
from src.structure.knowledge_graph_index import KGIndex


# from src.utils.data import RaggexxdBatch


def check_ldict(ldict):
    """
    Ldict is a nested dict that stores the GROUNDED information
    """
    assert 'op' in ldict
    op = ldict['op']
    assert 'args' in ldict
    args = ldict['args']

    if op == Term.op:
        assert 'name' in args
        assert 'state' in args
        assert 'entity_id_list' in args
    if op == BinaryPredicate.op:
        assert 'name' in args
        assert 'relation_id_list' in args
        check_ldict(args['term1'])
        check_ldict(args['term2'])
    if op == Negation.op:
        assert 'formula' in args
        check_ldict(args['formula'])
    if op == Conjunction.op or op == Disjunction.op:
        assert 'formulas' in args
        for f in args['formulas']:
            check_ldict(f)


def get_ldict(op, **args):
    ans = {'op': op, 'args': args}
    check_ldict(ans)
    return ans


class Lobject:
    op = "default"

    @abstractmethod
    def to_ldict(self) -> Dict:
        pass

    @abstractmethod
    def lstr(self) -> str:
        pass

    def __repr__(self):
        check_ldict(self.to_ldict())
        return json.dumps(self.to_ldict(), indent=1)

    @abstractmethod
    def get_predicates(self) -> Dict[str, 'BinaryPredicate']:
        pass


class Term(Lobject):
    EXISTENTIAL = 1
    FREE = 2
    UNIVERSAL = 3
    SYMBOL = 4
    # GROUNDED = 5

    op = "term"

    def __init__(self, state, name):
        self.state = state
        self.name = name
        self.parent_predicate = None
        self.entity_id_list = []

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        name = args['name']
        state = args['state']
        object = cls(name=name, state=state)
        object.entity_id_list = args['entity_id_list']
        return object

    def to_ldict(self):
        ldict = {'op': self.op,
                 'args': {
                     'state': self.state,
                     'name': self.name,
                     'entity_id_list': self.entity_id_list}}
        return ldict

    def lstr(self) -> str:
        return self.name

    @property
    def is_free(self):
        return self.state == self.FREE

    @property
    def is_existential(self):
        return self.state == self.EXISTENTIAL

    @property
    def is_universal(self):
        return self.state == self.UNIVERSAL

    @property
    def is_symbol(self):
        return self.state == self.SYMBOL

    @property
    def is_grounded(self):
        return self.is_symbol or (self.state == Term.GROUNDED)


class Formula(Lobject):
    def __init__(self) -> None:
        super().__init__()

    @staticmethod
    def parse(ldict):
        op = ldict['op']
        if op == BinaryPredicate.op:
            return BinaryPredicate.parse(ldict)
        elif op == Negation.op:
            return Negation.parse(ldict)
        elif op == Conjunction.op:
            return Conjunction.parse(ldict)
        elif op == Disjunction.op:
            return Disjunction.parse(ldict)
        else:
            raise NotImplementedError("Unsupported Operator")

    @property
    def num_predicates(self):
        pass


class BinaryPredicate(Formula):
    op = 'pred'

    def __init__(self,
                 name: str,
                 head: Term,
                 tail: Term) -> None:
        self.name = name
        self.head = head
        self.tail = tail
        self.relation_id_list = []
        self.skolem_negation = False

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']

        name = args['name']
        head = Term.parse(args['head'])
        tail = Term.parse(args['tail'])
        object = cls(name=name, head=head, tail=tail)
        object.relation_id_list = args['relation_id_list']
        head.parent_predicate = object
        tail.parent_predicate = object
        return object

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {
                'name': self.name,
                'relation_id_list': self.relation_id_list,
                'head': self.head.to_ldict(),
                'tail': self.tail.to_ldict()
            }
        }
        return obj

    def lstr(self):
        lstr = f"{self.name}({self.head.name},{self.tail.name})"
        return lstr

    def get_predicates(self) -> Dict[str, 'BinaryPredicate']:
        ans = {self.name: self}
        return ans

    def get_terms(self):
        return [self.head, self.tail]

    @property
    def num_predicates(self):
        return 1


class Connective(Formula):
    pass


class Negation(Connective):
    op = 'neg'

    def __init__(self, formula: Formula) -> None:
        self.formula = formula

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula = Formula.parse(args['formula'])
        if formula.op == 'pred':
            formula.skolem_negation = True
        return cls(formula)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formula': self.formula.to_ldict()}
        }
        return obj

    def lstr(self) -> str:
        lstr = f"!({self.formula.lstr()})"
        return lstr

    def get_predicates(self) -> Dict[str, 'BinaryPredicate']:
        ans = {}
        ans.update(self.formula.get_predicates())
        return ans

    @property
    def num_predicates(self):
        return self.formula.num_predicates


class Conjunction(Connective):  # TODO: Don't those formulas require a sorting of its sub formulas?
    op = 'conj'

    def __init__(self, formulas: List[Formula]) -> None:
        self.formulas = formulas

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula_dict_list = args['formulas']
        formulas = [Formula.parse(formula_dict)
                    for formula_dict in formula_dict_list]
        return cls(formulas)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formulas': [f.to_ldict() for f in self.formulas]}
        }
        return obj

    def lstr(self):
        lstr = "&".join(f"({f.lstr()})" for f in self.formulas)
        return lstr

    def get_predicates(self) -> Dict[str, 'BinaryPredicate']:
        ans = {}
        for f in self.formulas:
            ans.update(f.get_predicates())
        return ans

    @property
    def num_predicates(self):
        return sum([formula.num_predicates for formula in self.formulas])


class Disjunction(Connective):
    op = 'disj'

    def __init__(self, formulas: List[Formula]) -> None:
        self.formulas = formulas

    @classmethod
    def parse(cls, ldict):
        op = ldict['op']
        assert op == cls.op
        args = ldict['args']
        formula_dict_list = args['formulas']
        formulas = [Formula.parse(formula_dict)
                    for formula_dict in formula_dict_list]
        return cls(formulas)

    def to_ldict(self):
        obj = {
            'op': self.op,
            'args': {'formulas': [f.to_ldict() for f in self.formulas]}
        }
        return obj

    def lstr(self):
        lstr = "|".join(f"({f.lstr()})" for f in self.formulas)
        return lstr

    def get_predicates(self) -> Dict[str, 'BinaryPredicate']:
        ans = {}
        for f in self.formulas:
            ans.update(f.get_predicates())
        return ans

    @property
    def num_predicates(self):
        return sum([formula.num_predicates for formula in self.formulas])


class ConjunctiveFormula:
    """
    The first order formula is supposed to be without disjunction, since we always utilize the DNF normal form.
    it also includes information about the quantifiers

    self.formula is parsed from the formula and provide the operator tree for
        evaluation
    self.predicate_dict stores each predicates by its name, which are edges
    self.symbol_dict stores each symbol by its name
    self.variable_dict stores each variable by its name

    self.easy_answer_list list for easy answers
    self.hard_answer_list list for hard answers
    self.noisy_answer_list list for noisy answers

    each answer is a dict whose keys are the variable and values are the list of possible answers
    """

    def __init__(self,
                 formula: Formula) -> None:
        self.formula: Formula = formula
        self.easy_answer_list = []
        self.hard_answer_list = []
        self.noisy_answer_list = []
        self.grounding_dict_list = []

        # update internal storage
        self.predicate_dict: Dict[str, BinaryPredicate] = {}
        self.pred_grounded_relation_id_dict: Dict[str, List] = {}

        self.term_dict: Dict[str, Term] = {}
        self.term_grounded_entity_id_dict: Dict[str, List] = {}

        self.term_name2predicate_name_dict: Dict[str, str] = defaultdict(list)
        # run initialization
        self._init_query()

    def _init_query(self):
        self.predicate_dict = self.formula.get_predicates()
        self.pred_grounded_relation_id_dict = {
            name: predicate.relation_id_list
            for name, predicate in self.predicate_dict.items()
        }

        self.term_dict = {}
        for _, pred in self.predicate_dict.items():
            for t in pred.get_terms():
                self.term_dict[t.name] = t

        # self.term_local_embedding_dict = {name: None
        #   for name in self.term_dict}
        self.term_grounded_entity_id_dict = {name: term.entity_id_list
                                             for name, term in self.term_dict.items()}

        for pred_name, predicate in self.predicate_dict.items():
            head, tail = predicate.get_terms()
            self.term_name2predicate_name_dict[head.name].append(pred_name)
            self.term_name2predicate_name_dict[tail.name].append(pred_name)

    def append_relation_and_symbols(self, append_dict):
        for k, v in append_dict.items():
            if k in self.term_dict:
                self.term_grounded_entity_id_dict[k].append(v)
            else:
                self.pred_grounded_relation_id_dict[k].append(v)

    def pop_relation_and_symbols(self, index, pop_dict):
        for pop_key in pop_dict:
            if pop_key in self.term_dict:
                self.term_grounded_entity_id_dict[pop_key].pop(index)
            else:
                self.pred_grounded_relation_id_dict[pop_key].pop(index)

    def append_qa_instances(self,
                            append_dict,
                            easy_answers=[],
                            hard_answers=[],
                            noisy_answer=[]):
        self.append_relation_and_symbols(append_dict)
        self.easy_answer_list.append(easy_answers)
        self.hard_answer_list.append(hard_answers)
        self.noisy_answer_list.append(noisy_answer)

    def has_term_grounded_entity_id_list(self, key):
        return len(self.term_grounded_entity_id_dict[key]) > 0

    def get_term_grounded_entity_id_list(self, key):
        return self.term_grounded_entity_id_dict[key]

    def has_pred_grounded_relation_id_list(self, key):
        return len(self.pred_grounded_relation_id_dict[key]) > 0

    def get_pred_grounded_relation_id_list(self, key):
        return self.pred_grounded_relation_id_dict[key]

    def sample_query(self, data_kg: KnowledgeGraph, strict_meaningful_negation: bool):
        """
        Same relation should not exist multiple times!
        Very important so that we can ground entity then predicate, separately.
        """
        grounded_dict = {}
        sub_graph_edge, sub_graph_negation_edge = [], []
        for pred in self.predicate_dict.values():
            pred_triples = (pred.head.name, pred.name, pred.tail.name)
            if pred.skolem_negation:
                sub_graph_negation_edge.append(pred_triples)
            else:
                sub_graph_edge.append(pred_triples)
        sub_kg_index = KGIndex()
        sub_kg_index.map_entity_name_to_id = {term: 0 for term in self.term_dict}
        sub_kg_index.map_relation_name_to_id = {predicate: 0 for predicate in self.predicate_dict}
        labeled_pos_triples, node2index, index2node = labeling_triples(sub_graph_edge)
        sub_kg = KnowledgeGraph(labeled_pos_triples, sub_kg_index)
        sub_kg_matrix = kg2matrix(sub_kg)
        original_kg_matrix = kg2matrix(data_kg)
        node_be_anchor = [True if 's' in index2node[index] else False for index in index2node]
        grounded_entity_list, exist_grounding = ground_variable(sub_kg_matrix, original_kg_matrix)
        while not exist_grounding:
            grounded_entity_list, exist_grounding = ground_variable(sub_kg_matrix, original_kg_matrix)
        grounded_relation_dict = ground_predicate(grounded_entity_list, sub_kg, data_kg)
        grounded_entity_dict = {index2node[index]: int(grounded_entity_list[index])
                                for index in range(len(grounded_entity_list)) if node_be_anchor[index]}
        grounded_dict.update(grounded_relation_dict)
        grounded_dict.update(grounded_entity_dict)
        self.append_relation_and_symbols(grounded_dict)
        now_index = max([len(grounded) for grounded in self.term_grounded_entity_id_dict.values()]) - 1
        negation_pred_list = [negation_edge[1] for negation_edge in sub_graph_negation_edge]
        full_answer = self.deterministic_query(now_index, data_kg, negation_pred_list, True)
        self.pop_relation_and_symbols(now_index, grounded_dict)
        if not full_answer:
            return None
        if sub_graph_negation_edge:
            neg_edges = [[head, rel, tail, int(head not in node2index) + int(tail not in node2index)]
                                  for head, rel, tail in sub_graph_negation_edge]
            grounded_neg_pred = {rel: False for head, rel, tail in sub_graph_negation_edge}
            free_variable_ans = full_answer['f']
            sorted(neg_edges, key=lambda x: x[3])
            now_head, now_predicate, now_tail, not_in_node_num = neg_edges.pop(0)
            if not_in_node_num == 0:
                head_candidate, tail_candidate = full_answer[now_head], full_answer[now_tail]
                head_constraint = set.union(*[set(data_kg.node2or[head].keys()) for head in head_candidate])
                tail_constraint = set.union(*[set(data_kg.node2ir[tail].keys()) for tail in tail_candidate])
                neg_candidate_list = list(head_constraint.intersection(tail_constraint))
                random.shuffle(neg_candidate_list)
                for i in range(min(len(neg_candidate_list), 10)):
                    guess_predicate = neg_candidate_list[i]
                    grounded_dict[now_predicate] = guess_predicate
                    self.append_relation_and_symbols(grounded_dict)
                    full_answer = self.deterministic_query(
                        now_index, data_kg, [neg_edge[1] for neg_edge in neg_edges], True)
                    self.pop_relation_and_symbols(now_index, grounded_dict)
                    if full_answer['f'] and full_answer['f'] != free_variable_ans:
                        grounded_neg_pred[now_predicate] = True
                        break
                else:
                    guess_predicate = random.randint(0, data_kg.num_relations)
                    grounded_dict[now_predicate] = guess_predicate
            elif not_in_node_num == 1:
                if now_head in node2index:  # Tail is ungrounded anchor node
                    head_candidate = full_answer[now_head]
                    for now_try_time in range(10):
                        if len(head_candidate) > 1:
                            to_delete_head = random.sample(head_candidate, 1)[0]
                            guess_predicate = random.sample(data_kg.node2or[to_delete_head].keys(), 1)[0]
                            guess_tail = random.sample(data_kg.hr2t[(to_delete_head, guess_predicate)], 1)[0]
                        else:
                            guess_tail = random.randint(0, data_kg.num_entities)
                            guess_predicate = random.sample(data_kg.node2ir[guess_tail].keys(), 1)[0]
                        if len(head_candidate - data_kg.tr2h[(guess_tail, guess_predicate)]) > 0:
                            grounded_dict[now_tail] = guess_tail
                            grounded_dict[now_predicate] = guess_predicate
                            grounded_neg_pred[now_predicate] = True
                            node2index[now_tail] = len(node2index)
                            break
                    else:
                        guess_tail = random.randint(0, data_kg.num_entities)
                        guess_predicate = random.sample(data_kg.node2ir[guess_tail].keys(), 1)[0]
                        grounded_dict[now_tail] = guess_tail
                        grounded_dict[now_predicate] = guess_predicate
                        node2index[now_tail] = len(node2index)
                else:
                    tail_candidate = full_answer[now_tail]
                    for now_try_time in range(10):
                        if len(tail_candidate) > 1:
                            to_delete_tail = random.sample(tail_candidate, 1)[0]
                            guess_predicate = random.sample(data_kg.node2ir[to_delete_tail].keys(), 1)[0]
                            guess_head = random.sample(data_kg.tr2h[(to_delete_tail, guess_predicate)], 1)[0]
                        else:
                            guess_head = random.randint(0, data_kg.num_entities)
                            guess_predicate = random.sample(data_kg.node2or[guess_head].keys(), 1)[0]
                        if len(tail_candidate - data_kg.hr2t[(guess_head, guess_predicate)]) > 0:
                            grounded_dict[now_head] = guess_head
                            grounded_dict[now_predicate] = guess_predicate
                            grounded_neg_pred[now_predicate] = True
                            node2index[now_tail] = len(node2index)
                            break
                    else:
                        guess_head = random.randint(0, data_kg.num_entities)
                        guess_predicate = random.sample(data_kg.node2or[guess_head].keys(), 1)[0]
                        grounded_dict[now_head] = guess_head
                        grounded_dict[now_predicate] = guess_predicate
                        node2index[now_tail] = len(node2index)
            else:
                assert False, "There should not be an existential node that only connected to negation edge"
        if strict_meaningful_negation and sub_graph_negation_edge and False in grounded_neg_pred.values():
            return None
        return grounded_dict

    def sample_other_query(self, data_kg: KnowledgeGraph, existing_grounded_dict):
        """
        Since the answer is assured by the sample_query, this is sampled basically randomly.
        """
        for pred_name in self.predicate_dict:
            if pred_name not in existing_grounded_dict:
                pred = self.predicate_dict[pred_name]
                if pred.head.name in existing_grounded_dict:
                    head_constraint = set(data_kg.node2or[existing_grounded_dict[pred.head.name]].keys())
                else:
                    head_constraint = set(range(data_kg.num_relations))
                if pred.tail.name in existing_grounded_dict:
                    tail_constraint = set(data_kg.node2ir[existing_grounded_dict[pred.tail.name]].keys())
                else:
                    tail_constraint = set(range(data_kg.num_relations))
                pred_candidate = head_constraint.intersection(tail_constraint)
                grounded_pred = random.sample(pred_candidate, 1)[0]
                existing_grounded_dict[pred_name] = grounded_pred
        for node_name in self.term_dict:
            if 's' in node_name and node_name not in existing_grounded_dict:
                consider_edges = self.term_name2predicate_name_dict[node_name]
                node_constraint_list = []
                for edge in consider_edges:
                    if node_name == self.predicate_dict[edge].head.name:
                        new_constraint = data_kg.r2h[existing_grounded_dict[edge]]
                    else:
                        new_constraint = data_kg.r2t[existing_grounded_dict[edge]]
                    node_constraint_list.append(new_constraint)
                node_constraint = set.intersection(*node_constraint_list)
                node_candidate = random.sample(node_constraint, 1)[0]
                existing_grounded_dict[node_name] = node_candidate
        return existing_grounded_dict

    def deterministic_query(self, index, kg_graph: KnowledgeGraph, skip_predicate: List = [],
                            return_full_match: bool = False):
        """
        The skip predicate is used in grounding the predicate, it can avoids creating new instance of Formula.
        """
        now_term_candidate = defaultdict(set)
        for term_name in self.term_dict:
            if self.has_term_grounded_entity_id_list(term_name):
                now_term_candidate[term_name] = {self.term_grounded_entity_id_dict[term_name][index]}
            else:
                now_term_candidate[term_name] = set(range(kg_graph.num_entities))
        sub_graph_edge, sub_graph_negation_edge = [], []
        for pred in self.predicate_dict.values():
            if pred.name not in skip_predicate:
                pred_triples = (pred.head.name, self.pred_grounded_relation_id_dict[pred.name][index], pred.tail.name)
                if pred.skolem_negation:
                    sub_graph_negation_edge.append(pred_triples)
                else:
                    sub_graph_edge.append(pred_triples)
        sub_kg_index = KGIndex()
        sub_kg_index.map_entity_name_to_id = {term: 0 for term in self.term_dict}
        sub_kg_index.map_relation_name_to_id = {predicate: 0 for predicate in self.predicate_dict}
        sub_kg = KnowledgeGraph(sub_graph_edge, sub_kg_index)
        neg_kg = KnowledgeGraph(sub_graph_negation_edge, sub_kg_index)
        answer_dict, exist_answer = subgraph_matching(sub_kg, neg_kg, now_term_candidate, kg_graph)
        if return_full_match:
            to_return_ans = answer_dict if exist_answer else defaultdict(set)
            return to_return_ans
        else:
            answer_for_variable = answer_dict['f'] if exist_answer else {}
            return answer_for_variable

    @property
    def free_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.FREE}

    @property
    def universal_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.UNIVERSAL}

    @property
    def existential_variable_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.EXISTENTIAL}

    @property
    def symbol_dict(self):
        return {k: v
                for k, v in self.term_dict.items()
                if v.state == Term.SYMBOL}

    @property
    def is_sentence(self):
        """
        Determine the state of the formula
        A formula is sentence when all variables are quantified
        """
        return len({k: v for k, v in self.term_dict.items()
                    if v.state == Term.FREE}) == 0

    @property
    def lstr(self):
        return self.formula.lstr()

    @property
    def num_instances(self):
        num_instances = len(self.easy_answer_list)
        assert num_instances == len(self.hard_answer_list)
        for k in self.symbol_dict:
            assert num_instances == len(
                self.get_term_grounded_entity_id_list(k))

        for k in self.predicate_dict:
            assert num_instances == len(
                self.get_pred_grounded_relation_id_list(k))

        return len(self.easy_answer_list)

    @property
    def num_predicates(self):
        return self.formula.num_predicates

    @property
    def quantifier_rank(self):
        return len(self.existential_variable_dict) \
               + len(self.universal_variable_dict) \
               + len(self.free_variable_dict)

    def get_all_gounded_ids(self):
        entity_ids = []
        for term_name in self.term_grounded_entity_id_dict:
            entity_ids += self.term_grounded_entity_id_dict[term_name]
        relation_ids = []
        for pred_name in self.pred_grounded_relation_id_dict:
            relation_ids += self.pred_grounded_relation_id_dict[pred_name]
        return entity_ids, relation_ids


class DisjunctiveFormula:
    """
    We suppose the DNF formula is here, thus, no GNN computation is needed, all we need is gather the answer in each
    subformula.
    """

    def __init__(self,
                 formula_list: List[ConjunctiveFormula]) -> None:
        self.formula_list: List[ConjunctiveFormula] = formula_list
        self.easy_answer_list = []
        self.hard_answer_list = []
        self.noisy_answer_list = []
        self.grounding_dict_list = []

        # update internal storage
        self.predicate_dict: Dict[str, BinaryPredicate] = {}
        self.pred_grounded_relation_id_dict: Dict[str, List] = {}

        self.term_dict: Dict[str, Term] = {}
        self.term_grounded_entity_id_dict: Dict[str, List] = {}

        self.term_name2predicate_name_dict: Dict[str, str] = defaultdict(list)
        # run initialization
        self._init_query()

    def _init_query(self):
        easy_ans_set, hard_ans_set, noisy_ans_set = set(), set(), set()
        for formula in self.formula_list:
            easy_ans_set.update(set(formula.easy_answer_list))
            hard_ans_set.update(set(formula.hard_answer_list))
            noisy_ans_set.update(set(formula.noisy_answer_list))
        self.easy_answer_list, self.hard_answer_list, self.noisy_answer_list = list(easy_ans_set), list(hard_ans_set), \
                                                                               list(noisy_ans_set)

        self.predicate_dict = {}
        for sub_formula in self.formula_list:
            self.predicate_dict.update(sub_formula.formula.get_predicates())
        self.pred_grounded_relation_id_dict = {
            name: predicate.relation_id_list
            for name, predicate in self.predicate_dict.items()
        }

        self.term_dict = {}
        for _, pred in self.predicate_dict.items():
            for t in pred.get_terms():
                self.term_dict[t.name] = t

        self.term_grounded_entity_id_dict = {name: term.entity_id_list
                                             for name, term in self.term_dict.items()}

        for pred_name, predicate in self.predicate_dict.items():
            head, tail = predicate.get_terms()
            self.term_name2predicate_name_dict[head.name].append(pred_name)
            self.term_name2predicate_name_dict[tail.name].append(pred_name)

    def append_relation_and_symbols(self, append_dict):
        for sub_formula in self.formula_list:
            sub_append_dict = {key: append_dict[key] for key in append_dict if key in sub_formula.term_dict or
                               key in sub_formula.predicate_dict}
            sub_formula.append_relation_and_symbols(sub_append_dict)

    def append_qa_instances(self,
                            append_dict,
                            easy_answers=[],
                            hard_answers=[],
                            noisy_answer=[]):
        self.append_relation_and_symbols(append_dict)
        self.easy_answer_list.append(easy_answers)
        self.hard_answer_list.append(hard_answers)
        self.noisy_answer_list.append(noisy_answer)

    def sample_query(self, kg: KnowledgeGraph, strict_meaningful_negation: bool):
        selected_sub_formula_index = random.randint(0, len(self.formula_list) - 1)
        selected_sub_formula = self.formula_list[selected_sub_formula_index]
        grounded_dict = selected_sub_formula.sample_query(kg, strict_meaningful_negation)
        if not grounded_dict:
            return None
        for index in range(len(self.formula_list)):
            if index != selected_sub_formula_index:
                grounded_dict = self.formula_list[index].sample_other_query(kg, grounded_dict)
        return grounded_dict

    def deterministic_query(self, index, kg: KnowledgeGraph):
        all_answer = set()
        for sub_formula in self.formula_list:
            sub_answer = sub_formula.deterministic_query(index, kg)
            all_answer.update(sub_answer)
        return all_answer

    @property
    def lstr(self):
        if len(self.formula_list) == 1:
            lstr = self.formula_list[0].lstr
        else:
            lstr = "|".join(f"({f.lstr})" for f in self.formula_list)
        return lstr
